{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzHQvoEUQpncS6YRAXptXn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzXffKrKXlZe"
      },
      "outputs": [],
      "source": [
        "pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "#import random\n",
        "#random.seed(0)\n",
        "#import numpy as np\n",
        "#np.random.seed(0)\n",
        "\n",
        "train_data = pd.read_excel('data_sample_multiple_components_GLU_9objs.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "print(train_x)\n",
        "\n",
        "train_obj = train_data.iloc[:,2:].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "print(train_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgjIOYfLX5gC",
        "outputId": "7f1f42cc-eea2-4534-d1c8-85b041ae040b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000]])\n",
            "tensor([[ 0.0450,  0.0500,  0.0090,  0.0190,  0.1520,  0.0000,  0.0210,  0.0270,\n",
            "         -0.1990],\n",
            "        [ 0.0390,  0.0540,  0.0130,  0.0640,  0.1800,  0.0000,  0.0260,  0.0210,\n",
            "         -0.1990],\n",
            "        [ 0.0470,  0.0660,  0.0140,  0.0280,  0.2280,  0.0000,  0.0330,  0.0400,\n",
            "         -0.1990],\n",
            "        [ 0.0430,  0.0570,  0.0120,  0.0370,  0.1870,  0.0000,  0.0270,  0.0290,\n",
            "         -0.1990],\n",
            "        [ 0.0500,  0.0480,  0.0110,  0.0180,  0.2010,  0.0000,  0.0220,  0.0270,\n",
            "         -0.3740],\n",
            "        [ 0.0510,  0.0610,  0.0200,  0.0220,  0.2160,  0.0000,  0.0290,  0.0180,\n",
            "         -0.3870],\n",
            "        [ 0.0490,  0.0580,  0.0160,  0.0230,  0.2160,  0.0000,  0.0280,  0.0260,\n",
            "         -0.2970],\n",
            "        [ 0.0500,  0.0560,  0.0160,  0.0210,  0.2110,  0.0000,  0.0260,  0.0240,\n",
            "         -0.3530],\n",
            "        [ 0.0550,  0.0470,  0.0190,  0.0170,  0.2520,  0.0000,  0.0220,  0.0300,\n",
            "         -0.6280],\n",
            "        [ 0.0530,  0.0390,  0.0150,  0.0170,  0.1730,  0.0000,  0.0240,  0.0250,\n",
            "         -0.4530],\n",
            "        [ 0.0420,  0.0560,  0.0160,  0.0210,  0.2290,  0.0000,  0.0270,  0.0390,\n",
            "         -0.4000],\n",
            "        [ 0.0500,  0.0470,  0.0170,  0.0180,  0.2180,  0.0000,  0.0240,  0.0310,\n",
            "         -0.4930],\n",
            "        [ 0.0420,  0.0630,  0.0120,  0.0190,  0.2210,  0.0190,  0.0220,  0.0190,\n",
            "         -0.2590],\n",
            "        [ 0.0490,  0.0750,  0.0240,  0.0230,  0.1930,  0.0270,  0.0230,  0.0330,\n",
            "         -0.2180],\n",
            "        [ 0.0430,  0.0710,  0.0210,  0.0240,  0.2080,  0.0250,  0.0210,  0.0190,\n",
            "         -0.2180],\n",
            "        [ 0.0440,  0.0700,  0.0190,  0.0220,  0.2070,  0.0240,  0.0220,  0.0240,\n",
            "         -0.2310],\n",
            "        [ 0.0480,  0.0590,  0.0200,  0.0180,  0.2130,  0.0240,  0.0080,  0.0190,\n",
            "         -0.3770],\n",
            "        [ 0.0480,  0.0710,  0.0140,  0.0220,  0.2640,  0.0210,  0.0280,  0.0300,\n",
            "         -0.3740],\n",
            "        [ 0.0640,  0.0750,  0.0130,  0.0260,  0.1740,  0.0270,  0.0220,  0.0170,\n",
            "         -0.4390],\n",
            "        [ 0.0530,  0.0680,  0.0160,  0.0220,  0.2170,  0.0240,  0.0190,  0.0220,\n",
            "         -0.3970],\n",
            "        [ 0.0560,  0.0600,  0.0170,  0.0180,  0.2330,  0.0220,  0.0220,  0.0160,\n",
            "         -0.6040],\n",
            "        [ 0.0570,  0.0570,  0.0180,  0.0210,  0.1760,  0.0220,  0.0190,  0.0290,\n",
            "         -0.5320],\n",
            "        [ 0.0620,  0.0580,  0.0150,  0.0210,  0.1760,  0.0220,  0.0170,  0.0140,\n",
            "         -0.5740],\n",
            "        [ 0.0580,  0.0580,  0.0160,  0.0200,  0.1950,  0.0220,  0.0190,  0.0200,\n",
            "         -0.5700]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "NOISE_SE = torch.tensor([1,1,1,1,1,1,1,1,1])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.0])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhzxXF71YbNP",
        "outputId": "3dd88c34-c5f6-4a6e-be2e-409609eae80e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.8542e-02, 8.3327e-01],\n",
            "        [1.3619e-02, 2.5995e+00],\n",
            "        [1.9970e-02, 2.2111e-01],\n",
            "        [4.4772e-02, 2.0989e+00],\n",
            "        [3.1184e-02, 1.0067e+00],\n",
            "        [1.2088e-03, 3.8620e-01],\n",
            "        [4.0980e-03, 6.6677e-01],\n",
            "        [4.7046e-02, 1.7213e+00],\n",
            "        [3.3898e-02, 2.4039e+00],\n",
            "        [9.6460e-03, 2.4084e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9):\n",
        "    print(model.models[i].covar_module.outputscale, \n",
        "          model.models[i].covar_module.base_kernel.lengthscale, \n",
        "          model.models[i].likelihood.noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRxd77PXxTfu",
        "outputId": "9828727c-2cf6-4d3f-b7dc-383b7d190cf6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6369, grad_fn=<SoftplusBackward0>) tensor([[0.3329, 0.3337]], grad_fn=<SoftplusBackward0>) tensor([23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922,\n",
            "        23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922,\n",
            "        23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922,\n",
            "        23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922, 23962.4922])\n",
            "tensor(6.6329, grad_fn=<SoftplusBackward0>) tensor([[0.3339, 0.3332]], grad_fn=<SoftplusBackward0>) tensor([11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389,\n",
            "        11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389,\n",
            "        11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389,\n",
            "        11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389, 11423.8389])\n",
            "tensor(6.6523, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938,\n",
            "        82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938,\n",
            "        82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938,\n",
            "        82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938, 82449.5938])\n",
            "tensor(6.6182, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068,\n",
            "        10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068,\n",
            "        10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068,\n",
            "        10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068, 10739.5068])\n",
            "tensor(6.3253, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698,\n",
            "        1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698,\n",
            "        1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698,\n",
            "        1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698, 1422.2698])\n",
            "tensor(6.5875, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3334]], grad_fn=<SoftplusBackward0>) tensor([6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374,\n",
            "        6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374,\n",
            "        6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374,\n",
            "        6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374, 6957.8374])\n",
            "tensor(6.6460, grad_fn=<SoftplusBackward0>) tensor([[0.3329, 0.3337]], grad_fn=<SoftplusBackward0>) tensor([41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578,\n",
            "        41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578,\n",
            "        41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578,\n",
            "        41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578, 41001.2578])\n",
            "tensor(6.6434, grad_fn=<SoftplusBackward0>) tensor([[0.3335, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668,\n",
            "        21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668,\n",
            "        21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668,\n",
            "        21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668, 21159.9668])\n",
            "tensor(3.4514, grad_fn=<SoftplusBackward0>) tensor([[0.3339, 0.3366]], grad_fn=<SoftplusBackward0>) tensor([50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160,\n",
            "        50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160,\n",
            "        50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160, 50.2160])\n"
          ]
        }
      ]
    }
  ]
}