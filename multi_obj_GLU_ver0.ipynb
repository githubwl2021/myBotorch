{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMj8RWEzWRp73u6wduc1Qn2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb20WlrYZ944"
      },
      "outputs": [],
      "source": [
        "pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf\n",
        "\n",
        "NOISE_SE = torch.tensor([3, 3])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "train_data = pd.read_excel('data_sample_2components.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "#print(train_X)\n",
        "\n",
        "train_obj = train_data.iloc[:,[2,3]].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "#print(train_Y)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "#fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 3\n",
        "NUM_RESTARTS = 5\n",
        "RAW_SAMPLES = 20\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.001,0.1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSiQ89jaaMAS",
        "outputId": "18266c4f-d05c-452f-9245-93a69eb4fe3e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0208, 2.4566],\n",
            "        [0.0441, 1.3817],\n",
            "        [0.0225, 1.0460]])\n"
          ]
        }
      ]
    }
  ]
}