{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGN8pOz2s/6cSb5ezDsVDl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_aC0MJnIQKN"
      },
      "outputs": [],
      "source": [
        "pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "#import random\n",
        "#random.seed(0)\n",
        "#import numpy as np\n",
        "#np.random.seed(0)\n",
        "\n",
        "train_data = pd.read_excel('data_sample_multiple_components_withoutAverage_GLU_9objs_iter00.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "print(train_x)\n",
        "\n",
        "train_obj = train_data.iloc[:,2:].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "print(train_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY-o0yanIh_P",
        "outputId": "06f1c057-4313-4594-fc97-fe156c760911"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000]])\n",
            "tensor([[ 0.0450,  0.0500,  0.0090,  0.0190,  0.1520,  0.0000,  0.0210,  0.0270,\n",
            "         -0.1990],\n",
            "        [ 0.0390,  0.0540,  0.0130,  0.0640,  0.1800,  0.0000,  0.0260,  0.0210,\n",
            "         -0.1990],\n",
            "        [ 0.0470,  0.0660,  0.0140,  0.0280,  0.2280,  0.0000,  0.0330,  0.0400,\n",
            "         -0.1990],\n",
            "        [ 0.0500,  0.0480,  0.0110,  0.0180,  0.2010,  0.0000,  0.0220,  0.0270,\n",
            "         -0.3740],\n",
            "        [ 0.0510,  0.0610,  0.0200,  0.0220,  0.2160,  0.0000,  0.0290,  0.0180,\n",
            "         -0.3870],\n",
            "        [ 0.0490,  0.0580,  0.0160,  0.0230,  0.2160,  0.0000,  0.0280,  0.0260,\n",
            "         -0.2970],\n",
            "        [ 0.0550,  0.0470,  0.0190,  0.0170,  0.2520,  0.0000,  0.0220,  0.0300,\n",
            "         -0.6280],\n",
            "        [ 0.0530,  0.0390,  0.0150,  0.0170,  0.1730,  0.0000,  0.0240,  0.0250,\n",
            "         -0.4530],\n",
            "        [ 0.0420,  0.0560,  0.0160,  0.0210,  0.2290,  0.0000,  0.0270,  0.0390,\n",
            "         -0.4000],\n",
            "        [ 0.0420,  0.0630,  0.0120,  0.0190,  0.2210,  0.0190,  0.0220,  0.0190,\n",
            "         -0.2590],\n",
            "        [ 0.0490,  0.0750,  0.0240,  0.0230,  0.1930,  0.0270,  0.0230,  0.0330,\n",
            "         -0.2180],\n",
            "        [ 0.0430,  0.0710,  0.0210,  0.0240,  0.2080,  0.0250,  0.0210,  0.0190,\n",
            "         -0.2180],\n",
            "        [ 0.0480,  0.0590,  0.0200,  0.0180,  0.2130,  0.0240,  0.0080,  0.0190,\n",
            "         -0.3770],\n",
            "        [ 0.0480,  0.0710,  0.0140,  0.0220,  0.2640,  0.0210,  0.0280,  0.0300,\n",
            "         -0.3740],\n",
            "        [ 0.0640,  0.0750,  0.0130,  0.0260,  0.1740,  0.0270,  0.0220,  0.0170,\n",
            "         -0.4390],\n",
            "        [ 0.0560,  0.0600,  0.0170,  0.0180,  0.2330,  0.0220,  0.0220,  0.0160,\n",
            "         -0.6040],\n",
            "        [ 0.0570,  0.0570,  0.0180,  0.0210,  0.1760,  0.0220,  0.0190,  0.0290,\n",
            "         -0.5320],\n",
            "        [ 0.0620,  0.0580,  0.0150,  0.0210,  0.1760,  0.0220,  0.0170,  0.0140,\n",
            "         -0.5740]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement, qNoisyExpectedHypervolumeImprovement\n",
        "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list\n",
        "from botorch.acquisition.objective import GenericMCObjective\n",
        "from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n",
        "from botorch.utils.sampling import sample_simplex\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "NOISE_SE = torch.tensor([1,1,1,1,1,1,1,1,1])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.0])\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model.posterior(train_x).mean\n",
        "acq_func_list = []\n",
        "for _ in range(BATCH_SIZE):\n",
        "    #weights = sample_simplex(problem.num_objectives, **tkwargs).squeeze()\n",
        "    weights = sample_simplex(9).squeeze()\n",
        "    objective = GenericMCObjective(get_chebyshev_scalarization(weights=weights, Y=pred))\n",
        "    acq_func = qNoisyExpectedImprovement(  # pyre-ignore: [28]\n",
        "        model=model,\n",
        "        objective=objective,\n",
        "        X_baseline=train_x,\n",
        "        sampler=sampler,\n",
        "        prune_baseline=True,\n",
        "    )\n",
        "    acq_func_list.append(acq_func)\n",
        "# optimize\n",
        "candidates, _ = optimize_acqf_list(\n",
        "    acq_function_list=acq_func_list,\n",
        "    bounds=standard_bounds,\n",
        "    num_restarts=NUM_RESTARTS,\n",
        "    raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "    options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        ")\n",
        "\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZepTGzMyIoGq",
        "outputId": "06622d70-5654-45bb-a369-37d3d512480c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gpytorch/lazy/lazy_tensor.py:1810: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
            "X = torch.triangular_solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
            "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/gpytorch/utils/cholesky.py:42: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  NumericalWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e-03, 1.0000e-01],\n",
            "        [1.0000e-03, 3.0000e+00],\n",
            "        [5.0000e-02, 3.0000e+00],\n",
            "        [1.0000e-03, 2.9804e+00],\n",
            "        [1.9149e-02, 2.8527e+00],\n",
            "        [4.3758e-02, 2.8403e+00],\n",
            "        [4.0848e-02, 1.2879e+00],\n",
            "        [1.0000e-03, 1.6453e+00],\n",
            "        [4.6142e-02, 2.9380e+00],\n",
            "        [1.0000e-03, 1.0000e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9):\n",
        "    print(model.models[i].covar_module.outputscale, \n",
        "          model.models[i].covar_module.base_kernel.lengthscale, \n",
        "          model.models[i].likelihood.noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHTdRMXDJua1",
        "outputId": "3abde1a3-3bad-4ebb-d5c2-bd4ffed92425"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6402, grad_fn=<SoftplusBackward0>) tensor([[0.3331, 0.3335]], grad_fn=<SoftplusBackward0>) tensor([21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059,\n",
            "        21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059,\n",
            "        21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059])\n",
            "tensor(6.6283, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123,\n",
            "        10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123,\n",
            "        10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123])\n",
            "tensor(6.6605, grad_fn=<SoftplusBackward0>) tensor([[0.3332, 0.3335]], grad_fn=<SoftplusBackward0>) tensor([67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375,\n",
            "        67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375,\n",
            "        67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375])\n",
            "tensor(6.6182, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023,\n",
            "        8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023,\n",
            "        8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023])\n",
            "tensor(6.3322, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3334]], grad_fn=<SoftplusBackward0>) tensor([1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035,\n",
            "        1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035,\n",
            "        1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035])\n",
            "tensor(6.6052, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303,\n",
            "        6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303,\n",
            "        6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303])\n",
            "tensor(6.6561, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430,\n",
            "        33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430,\n",
            "        33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430])\n",
            "tensor(6.6453, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3334]], grad_fn=<SoftplusBackward0>) tensor([17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648,\n",
            "        17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648,\n",
            "        17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648])\n",
            "tensor(3.7316, grad_fn=<SoftplusBackward0>) tensor([[0.3337, 0.3359]], grad_fn=<SoftplusBackward0>) tensor([48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040,\n",
            "        48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040,\n",
            "        48.1040, 48.1040])\n"
          ]
        }
      ]
    }
  ]
}