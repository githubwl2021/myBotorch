{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLpZsk3dj9//HtqZKd7Qy3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uXV-wOWQDGc"
      },
      "outputs": [],
      "source": [
        "pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "train_data = pd.read_excel('data_sample_multiple_components.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "print(train_x)\n",
        "\n",
        "train_obj = train_data.iloc[:,2:].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "print(train_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cnf6rAgQVQh",
        "outputId": "4d87b2ea-1c93-4496-f73a-5fa2059e2abd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000]])\n",
            "tensor([[ 0.0450,  0.0500,  0.0090,  0.0190,  0.1520,  0.0010,  0.0210,  0.0270,\n",
            "         -0.1990],\n",
            "        [ 0.0390,  0.0540,  0.0130,  0.0640,  0.1800,  0.0010,  0.0260,  0.0210,\n",
            "         -0.1990],\n",
            "        [ 0.0470,  0.0660,  0.0140,  0.0280,  0.2280,  0.0010,  0.0330,  0.0400,\n",
            "         -0.1990],\n",
            "        [ 0.0430,  0.0570,  0.0120,  0.0370,  0.1870,  0.0010,  0.0270,  0.0290,\n",
            "         -0.1990],\n",
            "        [ 0.0500,  0.0480,  0.0110,  0.0180,  0.2010,  0.0010,  0.0220,  0.0270,\n",
            "         -0.3740],\n",
            "        [ 0.0510,  0.0610,  0.0200,  0.0220,  0.2160,  0.0010,  0.0290,  0.0180,\n",
            "         -0.3870],\n",
            "        [ 0.0490,  0.0580,  0.0160,  0.0230,  0.2160,  0.0010,  0.0280,  0.0260,\n",
            "         -0.2970],\n",
            "        [ 0.0500,  0.0560,  0.0160,  0.0210,  0.2110,  0.0010,  0.0260,  0.0240,\n",
            "         -0.3530],\n",
            "        [ 0.0550,  0.0470,  0.0190,  0.0170,  0.2520,  0.0010,  0.0220,  0.0300,\n",
            "         -0.6280],\n",
            "        [ 0.0530,  0.0390,  0.0150,  0.0170,  0.1730,  0.0010,  0.0240,  0.0250,\n",
            "         -0.4530],\n",
            "        [ 0.0420,  0.0560,  0.0160,  0.0210,  0.2290,  0.0010,  0.0270,  0.0390,\n",
            "         -0.4000],\n",
            "        [ 0.0500,  0.0470,  0.0170,  0.0180,  0.2180,  0.0010,  0.0240,  0.0310,\n",
            "         -0.4930],\n",
            "        [ 0.0420,  0.0630,  0.0120,  0.0190,  0.2210,  0.0190,  0.0220,  0.0190,\n",
            "         -0.2590],\n",
            "        [ 0.0490,  0.0750,  0.0240,  0.0230,  0.1930,  0.0270,  0.0230,  0.0330,\n",
            "         -0.2180],\n",
            "        [ 0.0430,  0.0710,  0.0210,  0.0240,  0.2080,  0.0250,  0.0210,  0.0190,\n",
            "         -0.2180],\n",
            "        [ 0.0440,  0.0700,  0.0190,  0.0220,  0.2070,  0.0240,  0.0220,  0.0240,\n",
            "         -0.2310],\n",
            "        [ 0.0480,  0.0590,  0.0200,  0.0180,  0.2130,  0.0240,  0.0080,  0.0190,\n",
            "         -0.3770],\n",
            "        [ 0.0480,  0.0710,  0.0140,  0.0220,  0.2640,  0.0210,  0.0280,  0.0300,\n",
            "         -0.3740],\n",
            "        [ 0.0640,  0.0750,  0.0130,  0.0260,  0.1740,  0.0270,  0.0220,  0.0170,\n",
            "         -0.4390],\n",
            "        [ 0.0530,  0.0680,  0.0160,  0.0220,  0.2170,  0.0240,  0.0190,  0.0220,\n",
            "         -0.3970],\n",
            "        [ 0.0560,  0.0600,  0.0170,  0.0180,  0.2330,  0.0220,  0.0220,  0.0160,\n",
            "         -0.6040],\n",
            "        [ 0.0570,  0.0570,  0.0180,  0.0210,  0.1760,  0.0220,  0.0190,  0.0290,\n",
            "         -0.5320],\n",
            "        [ 0.0620,  0.0580,  0.0150,  0.0210,  0.1760,  0.0220,  0.0170,  0.0140,\n",
            "         -0.5740],\n",
            "        [ 0.0580,  0.0580,  0.0160,  0.0200,  0.1950,  0.0220,  0.0190,  0.0200,\n",
            "         -0.5700]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf\n",
        "\n",
        "NOISE_SE = torch.tensor([1,1,1,1,1,1,1,1,1])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "#fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 5\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,-1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b555g3yQWiEt",
        "outputId": "2b2e963e-2516-4d38-8471-b57393a75b9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0407, 0.6501],\n",
            "        [0.0210, 2.9195],\n",
            "        [0.0253, 1.1993],\n",
            "        [0.0382, 2.7602],\n",
            "        [0.0306, 1.8583]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 6\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,-1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiGTEXlAa56x",
        "outputId": "7379752d-aa3b-4680-ae88-256a3816ea25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0410, 0.5438],\n",
            "        [0.0157, 2.6049],\n",
            "        [0.0225, 2.1782],\n",
            "        [0.0453, 2.8812],\n",
            "        [0.0182, 1.0176],\n",
            "        [0.0457, 1.9228]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 7\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,-1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKAzuScBbBoV",
        "outputId": "4dbc5317-3e23-4f3f-a23b-d77d0f293d31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0445, 0.6660],\n",
            "        [0.0421, 2.7245],\n",
            "        [0.0381, 1.8420],\n",
            "        [0.0399, 0.1174],\n",
            "        [0.0369, 1.4341],\n",
            "        [0.0096, 0.3995],\n",
            "        [0.0301, 0.8591]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,-1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6DcKFdxbMBO",
        "outputId": "c0e2624c-6d70-4694-d819-e0efebea2fd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0206, 0.1915],\n",
            "        [0.0267, 2.3496],\n",
            "        [0.0162, 1.2605],\n",
            "        [0.0317, 2.0304],\n",
            "        [0.0199, 2.9711],\n",
            "        [0.0141, 0.6094],\n",
            "        [0.0364, 2.2300],\n",
            "        [0.0199, 2.5874]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 9\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,-1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vRGav06bo66",
        "outputId": "80e18bb0-c178-4697-eab2-f047332a5d6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.3095e-02, 6.9522e-01],\n",
            "        [4.1864e-02, 2.8981e+00],\n",
            "        [1.9530e-02, 1.8174e-01],\n",
            "        [2.3179e-03, 2.2351e+00],\n",
            "        [1.7198e-03, 1.5639e+00],\n",
            "        [3.5096e-02, 1.3591e+00],\n",
            "        [3.4290e-02, 2.1119e+00],\n",
            "        [4.0977e-02, 2.5181e+00],\n",
            "        [2.8614e-02, 2.9633e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,-1])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iMvKsdlcKWP",
        "outputId": "6ebce70c-5c0b-40c5-d8ed-a1e20c2f5bc9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0470, 0.4857],\n",
            "        [0.0385, 2.6448],\n",
            "        [0.0457, 0.9128],\n",
            "        [0.0121, 0.6568],\n",
            "        [0.0368, 1.5865],\n",
            "        [0.0472, 0.1821],\n",
            "        [0.0228, 1.5860],\n",
            "        [0.0385, 1.8234],\n",
            "        [0.0451, 0.6220],\n",
            "        [0.0494, 2.2529]])\n"
          ]
        }
      ]
    }
  ]
}