{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLY3cS5cwSjPB1WFxuiMbd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B24CDlXOgoj7"
      },
      "outputs": [],
      "source": [
        "pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "#import random\n",
        "#random.seed(0)\n",
        "#import numpy as np\n",
        "#np.random.seed(0)\n",
        "\n",
        "train_data = pd.read_excel('data_sample_multiple_components_withoutAverage_GLU_9objs_iter00.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "print(train_x)\n",
        "\n",
        "train_obj = train_data.iloc[:,2:].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "print(train_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbvUj58mhJ19",
        "outputId": "4cde3834-246a-4894-bb78-3d1ae1e9164a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000]])\n",
            "tensor([[ 0.0450,  0.0500,  0.0090,  0.0190,  0.1520,  0.0000,  0.0210,  0.0270,\n",
            "         -0.1990],\n",
            "        [ 0.0390,  0.0540,  0.0130,  0.0640,  0.1800,  0.0000,  0.0260,  0.0210,\n",
            "         -0.1990],\n",
            "        [ 0.0470,  0.0660,  0.0140,  0.0280,  0.2280,  0.0000,  0.0330,  0.0400,\n",
            "         -0.1990],\n",
            "        [ 0.0500,  0.0480,  0.0110,  0.0180,  0.2010,  0.0000,  0.0220,  0.0270,\n",
            "         -0.3740],\n",
            "        [ 0.0510,  0.0610,  0.0200,  0.0220,  0.2160,  0.0000,  0.0290,  0.0180,\n",
            "         -0.3870],\n",
            "        [ 0.0490,  0.0580,  0.0160,  0.0230,  0.2160,  0.0000,  0.0280,  0.0260,\n",
            "         -0.2970],\n",
            "        [ 0.0550,  0.0470,  0.0190,  0.0170,  0.2520,  0.0000,  0.0220,  0.0300,\n",
            "         -0.6280],\n",
            "        [ 0.0530,  0.0390,  0.0150,  0.0170,  0.1730,  0.0000,  0.0240,  0.0250,\n",
            "         -0.4530],\n",
            "        [ 0.0420,  0.0560,  0.0160,  0.0210,  0.2290,  0.0000,  0.0270,  0.0390,\n",
            "         -0.4000],\n",
            "        [ 0.0420,  0.0630,  0.0120,  0.0190,  0.2210,  0.0190,  0.0220,  0.0190,\n",
            "         -0.2590],\n",
            "        [ 0.0490,  0.0750,  0.0240,  0.0230,  0.1930,  0.0270,  0.0230,  0.0330,\n",
            "         -0.2180],\n",
            "        [ 0.0430,  0.0710,  0.0210,  0.0240,  0.2080,  0.0250,  0.0210,  0.0190,\n",
            "         -0.2180],\n",
            "        [ 0.0480,  0.0590,  0.0200,  0.0180,  0.2130,  0.0240,  0.0080,  0.0190,\n",
            "         -0.3770],\n",
            "        [ 0.0480,  0.0710,  0.0140,  0.0220,  0.2640,  0.0210,  0.0280,  0.0300,\n",
            "         -0.3740],\n",
            "        [ 0.0640,  0.0750,  0.0130,  0.0260,  0.1740,  0.0270,  0.0220,  0.0170,\n",
            "         -0.4390],\n",
            "        [ 0.0560,  0.0600,  0.0170,  0.0180,  0.2330,  0.0220,  0.0220,  0.0160,\n",
            "         -0.6040],\n",
            "        [ 0.0570,  0.0570,  0.0180,  0.0210,  0.1760,  0.0220,  0.0190,  0.0290,\n",
            "         -0.5320],\n",
            "        [ 0.0620,  0.0580,  0.0150,  0.0210,  0.1760,  0.0220,  0.0170,  0.0140,\n",
            "         -0.5740]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "NOISE_SE = torch.tensor([1,1,1,1,1,1,1,1,1])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.0])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjY2Z8M6h4dC",
        "outputId": "159da5c2-a9a7-4492-a98e-0309a44e1fab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gpytorch/lazy/lazy_tensor.py:1810: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
            "X = torch.triangular_solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
            "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.8542e-02, 8.3327e-01],\n",
            "        [1.3619e-02, 2.5995e+00],\n",
            "        [1.9970e-02, 2.2111e-01],\n",
            "        [4.4772e-02, 2.0989e+00],\n",
            "        [3.1184e-02, 1.0067e+00],\n",
            "        [1.2088e-03, 3.8620e-01],\n",
            "        [4.0980e-03, 6.6677e-01],\n",
            "        [4.7046e-02, 1.7213e+00],\n",
            "        [3.3898e-02, 2.4039e+00],\n",
            "        [9.6460e-03, 2.4084e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9):\n",
        "    print(model.models[i].covar_module.outputscale, \n",
        "          model.models[i].covar_module.base_kernel.lengthscale, \n",
        "          model.models[i].likelihood.noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLGF9KxXipiT",
        "outputId": "6b918e99-087e-42ed-dd69-452107cc1649"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6402, grad_fn=<SoftplusBackward0>) tensor([[0.3331, 0.3335]], grad_fn=<SoftplusBackward0>) tensor([21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059,\n",
            "        21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059,\n",
            "        21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059, 21197.0059])\n",
            "tensor(6.6283, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123,\n",
            "        10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123,\n",
            "        10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123, 10278.1123])\n",
            "tensor(6.6605, grad_fn=<SoftplusBackward0>) tensor([[0.3332, 0.3335]], grad_fn=<SoftplusBackward0>) tensor([67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375,\n",
            "        67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375,\n",
            "        67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375, 67208.4375])\n",
            "tensor(6.6182, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023,\n",
            "        8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023,\n",
            "        8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023, 8917.9023])\n",
            "tensor(6.3322, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3334]], grad_fn=<SoftplusBackward0>) tensor([1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035,\n",
            "        1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035,\n",
            "        1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035, 1104.0035])\n",
            "tensor(6.6052, grad_fn=<SoftplusBackward0>) tensor([[0.3333, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303,\n",
            "        6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303,\n",
            "        6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303, 6837.5303])\n",
            "tensor(6.6561, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3333]], grad_fn=<SoftplusBackward0>) tensor([33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430,\n",
            "        33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430,\n",
            "        33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430, 33864.5430])\n",
            "tensor(6.6453, grad_fn=<SoftplusBackward0>) tensor([[0.3334, 0.3334]], grad_fn=<SoftplusBackward0>) tensor([17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648,\n",
            "        17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648,\n",
            "        17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648, 17017.9648])\n",
            "tensor(3.7316, grad_fn=<SoftplusBackward0>) tensor([[0.3337, 0.3359]], grad_fn=<SoftplusBackward0>) tensor([48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040,\n",
            "        48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040, 48.1040,\n",
            "        48.1040, 48.1040])\n"
          ]
        }
      ]
    }
  ]
}