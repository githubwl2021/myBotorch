{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOO9misQl15/EMMI5BJxURa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLqnkqIGzsvk"
      },
      "outputs": [],
      "source": [
        "pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "train_data = pd.read_excel('data_sample_multiple_components_GLU.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "print(train_x)\n",
        "\n",
        "train_obj = train_data.iloc[:,2:].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "print(train_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev2p1aOS0EZh",
        "outputId": "de9d28cd-7cac-4fa4-d2cd-445a91112416"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000]])\n",
            "tensor([[ 0.0450,  0.0500,  0.0090,  0.0190,  0.1520,  0.0000,  0.0210,  0.0270,\n",
            "         -0.1990],\n",
            "        [ 0.0390,  0.0540,  0.0130,  0.0640,  0.1800,  0.0000,  0.0260,  0.0210,\n",
            "         -0.1990],\n",
            "        [ 0.0470,  0.0660,  0.0140,  0.0280,  0.2280,  0.0000,  0.0330,  0.0400,\n",
            "         -0.1990],\n",
            "        [ 0.0430,  0.0570,  0.0120,  0.0370,  0.1870,  0.0000,  0.0270,  0.0290,\n",
            "         -0.1990],\n",
            "        [ 0.0500,  0.0480,  0.0110,  0.0180,  0.2010,  0.0000,  0.0220,  0.0270,\n",
            "         -0.3740],\n",
            "        [ 0.0510,  0.0610,  0.0200,  0.0220,  0.2160,  0.0000,  0.0290,  0.0180,\n",
            "         -0.3870],\n",
            "        [ 0.0490,  0.0580,  0.0160,  0.0230,  0.2160,  0.0000,  0.0280,  0.0260,\n",
            "         -0.2970],\n",
            "        [ 0.0500,  0.0560,  0.0160,  0.0210,  0.2110,  0.0000,  0.0260,  0.0240,\n",
            "         -0.3530],\n",
            "        [ 0.0550,  0.0470,  0.0190,  0.0170,  0.2520,  0.0000,  0.0220,  0.0300,\n",
            "         -0.6280],\n",
            "        [ 0.0530,  0.0390,  0.0150,  0.0170,  0.1730,  0.0000,  0.0240,  0.0250,\n",
            "         -0.4530],\n",
            "        [ 0.0420,  0.0560,  0.0160,  0.0210,  0.2290,  0.0000,  0.0270,  0.0390,\n",
            "         -0.4000],\n",
            "        [ 0.0500,  0.0470,  0.0170,  0.0180,  0.2180,  0.0000,  0.0240,  0.0310,\n",
            "         -0.4930],\n",
            "        [ 0.0420,  0.0630,  0.0120,  0.0190,  0.2210,  0.0190,  0.0220,  0.0190,\n",
            "         -0.2590],\n",
            "        [ 0.0490,  0.0750,  0.0240,  0.0230,  0.1930,  0.0270,  0.0230,  0.0330,\n",
            "         -0.2180],\n",
            "        [ 0.0430,  0.0710,  0.0210,  0.0240,  0.2080,  0.0250,  0.0210,  0.0190,\n",
            "         -0.2180],\n",
            "        [ 0.0440,  0.0700,  0.0190,  0.0220,  0.2070,  0.0240,  0.0220,  0.0240,\n",
            "         -0.2310],\n",
            "        [ 0.0480,  0.0590,  0.0200,  0.0180,  0.2130,  0.0240,  0.0080,  0.0190,\n",
            "         -0.3770],\n",
            "        [ 0.0480,  0.0710,  0.0140,  0.0220,  0.2640,  0.0210,  0.0280,  0.0300,\n",
            "         -0.3740],\n",
            "        [ 0.0640,  0.0750,  0.0130,  0.0260,  0.1740,  0.0270,  0.0220,  0.0170,\n",
            "         -0.4390],\n",
            "        [ 0.0530,  0.0680,  0.0160,  0.0220,  0.2170,  0.0240,  0.0190,  0.0220,\n",
            "         -0.3970],\n",
            "        [ 0.0560,  0.0600,  0.0170,  0.0180,  0.2330,  0.0220,  0.0220,  0.0160,\n",
            "         -0.6040],\n",
            "        [ 0.0570,  0.0570,  0.0180,  0.0210,  0.1760,  0.0220,  0.0190,  0.0290,\n",
            "         -0.5320],\n",
            "        [ 0.0620,  0.0580,  0.0150,  0.0210,  0.1760,  0.0220,  0.0170,  0.0140,\n",
            "         -0.5740],\n",
            "        [ 0.0580,  0.0580,  0.0160,  0.0200,  0.1950,  0.0220,  0.0190,  0.0200,\n",
            "         -0.5700]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf\n",
        "\n",
        "NOISE_SE = torch.tensor([1,1,1,1,1,1,1,1,1])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.0])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm1G_CNK0cc4",
        "outputId": "37795a38-4656-471d-f6fc-f77471a5a131"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0035, 0.5932],\n",
            "        [0.0247, 0.3254],\n",
            "        [0.0241, 2.5365],\n",
            "        [0.0266, 0.9060],\n",
            "        [0.0076, 0.4139],\n",
            "        [0.0453, 2.2653],\n",
            "        [0.0127, 0.1740],\n",
            "        [0.0407, 1.4142],\n",
            "        [0.0226, 2.9808],\n",
            "        [0.0077, 2.0370]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "train_data = pd.read_excel('data_sample_multiple_components_FRUC.xlsx')\n",
        "#print(train_data)\n",
        "train_x = train_data.iloc[:,[0,1]].values\n",
        "#print(train_X)\n",
        "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "print(train_x)\n",
        "\n",
        "train_obj = train_data.iloc[:,2:].values\n",
        "#print(train_Y)\n",
        "train_obj = torch.tensor(train_obj, dtype=torch.float32)\n",
        "print(train_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf_Wi0dU2JLJ",
        "outputId": "903b810e-430a-4a40-d6ad-8fd1a0b3c680"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 0.5000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 1.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0050, 2.0000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 0.5000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 1.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000],\n",
            "        [0.0406, 2.0000]])\n",
            "tensor([[ 0.2710,  0.9010,  0.0270,  0.0360,  0.2140,  0.0000,  0.0280,  0.0320,\n",
            "         -0.0600],\n",
            "        [ 0.2940,  0.9410,  0.0280,  0.0330,  0.1750,  0.0000,  0.0000,  0.0200,\n",
            "         -0.0810],\n",
            "        [ 0.2890,  0.9780,  0.0260,  0.0370,  0.1690,  0.0000,  0.0000,  0.0220,\n",
            "         -0.0810],\n",
            "        [ 0.2850,  0.9400,  0.0270,  0.0350,  0.1860,  0.0000,  0.0280,  0.0250,\n",
            "         -0.0740],\n",
            "        [ 0.4350,  1.4830,  0.0430,  0.0480,  0.2330,  0.0000,  0.0310,  0.0310,\n",
            "         -0.0970],\n",
            "        [ 0.6060,  2.0620,  0.0310,  0.0410,  0.3250,  0.0000,  0.0000,  0.0240,\n",
            "         -0.1340],\n",
            "        [ 0.4670,  1.7330,  0.0450,  0.0430,  0.2100,  0.0000,  0.0000,  0.0240,\n",
            "         -0.1020],\n",
            "        [ 0.5020,  1.7590,  0.0400,  0.0440,  0.2560,  0.0000,  0.0310,  0.0260,\n",
            "         -0.1110],\n",
            "        [ 0.5900,  2.0550,  0.0570,  0.0520,  0.2830,  0.0000,  0.0350,  0.0340,\n",
            "         -0.1160],\n",
            "        [ 0.6060,  2.0620,  0.0490,  0.0410,  0.3250,  0.0000,  0.0220,  0.0230,\n",
            "         -0.1340],\n",
            "        [ 0.5410,  1.9560,  0.0490,  0.0380,  0.1940,  0.0000,  0.0210,  0.0250,\n",
            "         -0.1400],\n",
            "        [ 0.5790,  2.0240,  0.0510,  0.0440,  0.2670,  0.0000,  0.0260,  0.0280,\n",
            "         -0.1300],\n",
            "        [ 0.3150,  1.6160,  0.0400,  0.0860,  0.4830,  0.0430,  0.0280,  0.0320,\n",
            "         -0.0960],\n",
            "        [ 0.3290,  1.7690,  0.0280,  0.0980,  0.4620,  0.0570,  0.0430,  0.0380,\n",
            "         -0.1350],\n",
            "        [ 0.3820,  2.1010,  0.0450,  0.1050,  0.5610,  0.0570,  0.0490,  0.0430,\n",
            "         -0.1490],\n",
            "        [ 0.3420,  1.8290,  0.0380,  0.0970,  0.5020,  0.0520,  0.0400,  0.0380,\n",
            "         -0.1270],\n",
            "        [ 0.4780,  2.2440,  0.0640,  0.0890,  0.4080,  0.0460,  0.0290,  0.0300,\n",
            "         -0.1390],\n",
            "        [ 0.5420,  2.8680,  0.0700,  0.1230,  0.5510,  0.0620,  0.0360,  0.0360,\n",
            "         -0.1950],\n",
            "        [ 0.5070,  2.7440,  0.0760,  0.1290,  0.6320,  0.0640,  0.0440,  0.0370,\n",
            "         -0.1830],\n",
            "        [ 0.5090,  2.6190,  0.0700,  0.1130,  0.5300,  0.0570,  0.0360,  0.0340,\n",
            "         -0.1720],\n",
            "        [ 0.6170,  2.4900,  0.0580,  0.0870,  0.3810,  0.0720,  0.0250,  0.0280,\n",
            "         -0.2200],\n",
            "        [ 0.6700,  3.3670,  0.0660,  0.1070,  0.4020,  0.0650,  0.0390,  0.0360,\n",
            "         -0.2090],\n",
            "        [ 0.5340,  2.8380,  0.0510,  0.0970,  0.3720,  0.0580,  0.0290,  0.0280,\n",
            "         -0.1850],\n",
            "        [ 0.6070,  2.8980,  0.0580,  0.0970,  0.3850,  0.0650,  0.0310,  0.0310,\n",
            "         -0.2050]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch import fit_gpytorch_model\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.transforms import unnormalize, normalize\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
        "from botorch.optim.optimize import optimize_acqf\n",
        "\n",
        "NOISE_SE = torch.tensor([1,1,1,1,1,1,1,1,1])\n",
        "#print(NOISE_SE)\n",
        "\n",
        "# define models for objective and constraint\n",
        "models = []\n",
        "for i in range(train_obj.shape[-1]):\n",
        "    train_y = train_obj[..., i:i+1]\n",
        "    train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
        "    models.append(FixedNoiseGP(train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)))\n",
        "model = ModelListGP(*models)\n",
        "mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_model(mll)\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "NUM_RESTARTS = 2\n",
        "RAW_SAMPLES = 4\n",
        "MC_SAMPLES = 16\n",
        "\n",
        "standard_bounds = torch.tensor([[0.001, 0.1],[0.05, 3]])\n",
        "#print(standard_bounds)\n",
        "ref_point=torch.tensor([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.0])\n",
        "\n",
        "with torch.no_grad():\n",
        "  #pred = model.posterior(normalize(train_x, standard_bounds)).mean\n",
        "  pred = model.posterior(train_x).mean\n",
        "partitioning = FastNondominatedPartitioning(ref_point, Y=pred)\n",
        "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
        "acq_func = qExpectedHypervolumeImprovement(model,ref_point,partitioning,sampler)\n",
        "\n",
        "candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=standard_bounds,\n",
        "        q=BATCH_SIZE,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
        "        #options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True)\n",
        "#candidates =  unnormalize(candidates.detach(), bounds=standard_bounds)\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2_cZAs92oxS",
        "outputId": "d7c53dae-76a8-4305-dc3b-2c753a9ab79e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.9689e-02, 9.9003e-01],\n",
            "        [4.6220e-02, 2.5775e+00],\n",
            "        [1.8763e-02, 2.7416e+00],\n",
            "        [1.8268e-02, 1.1262e+00],\n",
            "        [8.5614e-03, 1.7171e+00],\n",
            "        [1.3781e-03, 2.8373e+00],\n",
            "        [4.7136e-02, 2.3496e+00],\n",
            "        [4.6376e-02, 2.3202e+00],\n",
            "        [1.9267e-02, 9.7993e-01],\n",
            "        [3.6715e-02, 2.0726e+00]])\n"
          ]
        }
      ]
    }
  ]
}